{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ab8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f0227",
   "metadata": {},
   "source": [
    "Initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dfc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame to store the dataset and use number to represent a class\n",
    "def initImg(root, matrix_label):\n",
    "    label_lst, class_lst, img_lst = [], [], []\n",
    "    label = 0\n",
    "    for file in os.listdir(root):\n",
    "        class_path = os.path.join(root, file)\n",
    "        for fn in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, fn)\n",
    "            img_lst.append(img_path)\n",
    "            class_lst.append(file)\n",
    "            if file not in matrix_label:\n",
    "                matrix_label.append(file)\n",
    "            label_lst.append(label)\n",
    "        label += 1\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"filename\": img_lst,\n",
    "        \"class\": class_lst,\n",
    "        \"label\": label_lst\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246c1a7",
   "metadata": {},
   "source": [
    "Feature Extraction Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a35ea",
   "metadata": {},
   "source": [
    "- SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844ea57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the dataset and get descriptors for each image and build histogram\n",
    "def preprocessImg(img):\n",
    "    blurred = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    laplacian = cv2.Laplacian(blurred, cv2.CV_64F)\n",
    "    laplacian = cv2.convertScaleAbs(laplacian)\n",
    "    sharpened = cv2.addWeighted(img, 1, laplacian, 1.0, 0)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_img = clahe.apply(sharpened)\n",
    "    return clahe_img\n",
    "\n",
    "\n",
    "def build_bow_histogram(descriptors, kmeans, n_clusters):\n",
    "    if descriptors is None:\n",
    "        return np.zeros(n_clusters)\n",
    "\n",
    "    descriptors = np.asarray(descriptors, dtype=np.float32)\n",
    "    words = kmeans.predict(descriptors)\n",
    "\n",
    "    histogram, _ = np.histogram(words, bins=np.arange(n_clusters + 1))\n",
    "\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def get_descriptors(img_path, preprocess=True):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if preprocess:\n",
    "        gray = preprocessImg(gray)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def descriptorlst(train_df):\n",
    "    descriptor_lst = []\n",
    "\n",
    "    for _, row in train_df.iterrows():\n",
    "        descriptors = get_descriptors(row['filename'], preprocess=True)\n",
    "        if descriptors is not None:\n",
    "            descriptor_lst.extend(descriptors)\n",
    "    descriptor_lst = np.asarray(descriptor_lst, dtype=np.float32)\n",
    "\n",
    "    return descriptor_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8caec33",
   "metadata": {},
   "source": [
    "- LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370dbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 1\n",
    "n_points = 8 * radius\n",
    "method = 'uniform'\n",
    "\n",
    "def extract_lbp_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method).astype(np.uint8)\n",
    "\n",
    "    hist = cv2.calcHist([lbp], [0], None, [n_points + 2], [0, n_points + 2])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa75d6",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a23871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(data, preprocess):\n",
    "    train_df, test_df = train_test_split(\n",
    "        data,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=data['label']\n",
    "    )\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "    if preprocess == 'sift':\n",
    "        descriptor_lst = descriptorlst(train_df)\n",
    "        kmeans = MiniBatchKMeans(n_clusters=100, random_state=42)\n",
    "        kmeans.fit(descriptor_lst)\n",
    "        for df, X, y in [(train_df, X_train, y_train), (test_df, X_test, y_test)]:\n",
    "            for _, row in df.iterrows():\n",
    "                descriptors = get_descriptors(row['filename'], preprocess=False)\n",
    "                hist = build_bow_histogram(descriptors, kmeans, 100)\n",
    "                X.append(hist)\n",
    "                y.append(row['label'])\n",
    "\n",
    "    elif preprocess == 'lbp':\n",
    "         for df, X, y in [(train_df, X_train, y_train), (test_df, X_test, y_test)]:\n",
    "            for _, row in df.iterrows():\n",
    "                features = extract_lbp_features(row['filename'])\n",
    "                X.append(features)\n",
    "                y.append(row['label'])\n",
    "\n",
    "    return np.array(X_train), y_train, np.array(X_test), y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff787ceb",
   "metadata": {},
   "source": [
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=matrix_lst, yticklabels=matrix_lst)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190c17af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for SIFT Features ===\n",
      "\n",
      "-- Logistic Regression --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LeeX0\\.conda\\envs\\COMP9517\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6241666666666666\n",
      "Precision: 0.6256437588083007\n",
      "Recall: 0.6241666666666669\n",
      "F1 Score: 0.6222975678636975\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59       160\n",
      "           1       0.54      0.50      0.52       160\n",
      "           2       0.65      0.61      0.63       160\n",
      "           3       0.69      0.64      0.66       160\n",
      "           4       0.46      0.56      0.51       160\n",
      "           5       0.84      0.74      0.79       160\n",
      "           6       0.47      0.65      0.55       160\n",
      "           7       0.59      0.59      0.59       160\n",
      "           8       0.36      0.28      0.31       160\n",
      "           9       0.75      0.72      0.73       160\n",
      "          10       0.87      0.90      0.88       160\n",
      "          11       0.71      0.64      0.68       160\n",
      "          12       0.68      0.69      0.69       160\n",
      "          13       0.72      0.84      0.78       160\n",
      "          14       0.47      0.40      0.43       160\n",
      "\n",
      "    accuracy                           0.62      2400\n",
      "   macro avg       0.63      0.62      0.62      2400\n",
      "weighted avg       0.63      0.62      0.62      2400\n",
      "\n",
      "\n",
      "-- KNN --\n",
      "Accuracy: 0.5791666666666667\n",
      "Precision: 0.5837314035918362\n",
      "Recall: 0.5791666666666667\n",
      "F1 Score: 0.5734706182223035\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.70      0.59       160\n",
      "           1       0.40      0.47      0.43       160\n",
      "           2       0.58      0.53      0.55       160\n",
      "           3       0.58      0.74      0.65       160\n",
      "           4       0.42      0.51      0.46       160\n",
      "           5       0.82      0.81      0.82       160\n",
      "           6       0.53      0.64      0.58       160\n",
      "           7       0.57      0.44      0.49       160\n",
      "           8       0.35      0.24      0.28       160\n",
      "           9       0.64      0.68      0.66       160\n",
      "          10       0.96      0.67      0.79       160\n",
      "          11       0.75      0.54      0.63       160\n",
      "          12       0.63      0.67      0.65       160\n",
      "          13       0.67      0.83      0.74       160\n",
      "          14       0.34      0.23      0.27       160\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.58      0.58      0.57      2400\n",
      "weighted avg       0.58      0.58      0.57      2400\n",
      "\n",
      "\n",
      "=== Results for LBP Features ===\n",
      "\n",
      "-- Logistic Regression --\n",
      "Accuracy: 0.4175\n",
      "Precision: 0.40881482813908454\n",
      "Recall: 0.41750000000000004\n",
      "F1 Score: 0.3879199940137815\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51       160\n",
      "           1       0.26      0.14      0.18       160\n",
      "           2       0.33      0.14      0.19       160\n",
      "           3       0.29      0.06      0.10       160\n",
      "           4       0.38      0.60      0.47       160\n",
      "           5       0.47      0.75      0.57       160\n",
      "           6       0.45      0.56      0.50       160\n",
      "           7       0.36      0.35      0.36       160\n",
      "           8       0.57      0.39      0.46       160\n",
      "           9       0.32      0.62      0.43       160\n",
      "          10       0.38      0.55      0.45       160\n",
      "          11       0.62      0.69      0.65       160\n",
      "          12       0.36      0.54      0.43       160\n",
      "          13       0.48      0.31      0.37       160\n",
      "          14       0.31      0.08      0.13       160\n",
      "\n",
      "    accuracy                           0.42      2400\n",
      "   macro avg       0.41      0.42      0.39      2400\n",
      "weighted avg       0.41      0.42      0.39      2400\n",
      "\n",
      "\n",
      "-- KNN --\n",
      "Accuracy: 0.505\n",
      "Precision: 0.5055403863580186\n",
      "Recall: 0.505\n",
      "F1 Score: 0.5003941045437402\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.59      0.53       160\n",
      "           1       0.30      0.32      0.31       160\n",
      "           2       0.41      0.45      0.43       160\n",
      "           3       0.40      0.53      0.46       160\n",
      "           4       0.56      0.55      0.55       160\n",
      "           5       0.69      0.81      0.75       160\n",
      "           6       0.70      0.61      0.65       160\n",
      "           7       0.42      0.39      0.41       160\n",
      "           8       0.53      0.49      0.51       160\n",
      "           9       0.49      0.61      0.54       160\n",
      "          10       0.58      0.39      0.47       160\n",
      "          11       0.70      0.67      0.68       160\n",
      "          12       0.49      0.37      0.42       160\n",
      "          13       0.53      0.59      0.56       160\n",
      "          14       0.31      0.19      0.24       160\n",
      "\n",
      "    accuracy                           0.51      2400\n",
      "   macro avg       0.51      0.51      0.50      2400\n",
      "weighted avg       0.51      0.51      0.50      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_models(X_train, y_train, X_test, y_test, descriptor_name):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== Results for {descriptor_name.upper()} Features ===\")\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n-- {model_name} --\")\n",
    "        model.fit(X_train, y_train)\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "\n",
    "\n",
    "# Initialize dataset\n",
    "root_dir = 'Aerial_Landscapes'\n",
    "matrix_label = []\n",
    "df = initImg(root_dir, matrix_label)\n",
    "\n",
    "# Run for both SIFT and LBP\n",
    "for descriptor_type in ['sift', 'lbp']:\n",
    "    X_train, y_train, X_test, y_test = dataloader(df, preprocess=descriptor_type)\n",
    "    run_models(X_train, y_train, X_test, y_test, descriptor_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP9517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
